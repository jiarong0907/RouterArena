{
    "pipeline_params": {
        "router_name": "vllm",
        "models": {
            "meta-llama/llama-3-8b-instruct": 0.03498,
            "mistralai/mistral-7b-chat": 0.08101,
            "meta/llama-3-70b-chat": 0.2896,
            "Qwen_Qwen2.5-72B-Instruct": 0.388,
            "mistralai/mixtral-8x7b-chat": 0.2262,
            "llama-3-1-405b-instruct": 0.8469,
            "openai/gpt-4o": 1.436,
            "anthropic_claude-3.5-sonnet": 2.677
        }

    }
}
